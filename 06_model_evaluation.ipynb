{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Databricks notebook source\n",
        "\n",
        "## 1. Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# https://www.nature.com/articles/s41598-022-15245-z\n",
        "# https://www.nannyml.com/blog/91-of-ml-perfomance-degrade-in-time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install u8darts[all]==0.29.0\n",
        "!pip install mlflow==2.11.3\n",
        "dbutils.library.restartPython()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Darts\n",
        "from darts import TimeSeries\n",
        "from darts.models.forecasting.lgbm import LightGBMModel\n",
        "from darts import TimeSeries\n",
        "from darts import metrics\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "\n",
        "# Analysis\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "# Utilities\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow.tracking import MlflowClient\n",
        "from datetime import timedelta\n",
        "import datetime\n",
        "import holidays\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import MinMaxScaler, PowerTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "# Notebook configuration\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 2. Data Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importing actual values\n",
        "str_select_sales = '''\n",
        "                        SELECT *\n",
        "                        FROM analytics.refined_sales_orders_agg\n",
        "                        '''\n",
        "\n",
        "df_series_sales = spark.sql(str_select_sales).toPandas()\n",
        "\n",
        "# Setting SYSTEM_TIMESTAMP column as DataFrame index\n",
        "df_series_sales.set_index('SYSTEM_TIMESTAMP', inplace=True)\n",
        "df_series_sales.sort_index(inplace=True)\n",
        "\n",
        "# Converts granularity to Daily\n",
        "df_series_sales_resampled = df_series_sales.resample('D').sum()\n",
        "\n",
        "df_series_sales_resampled.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importing predicted values\n",
        "str_select_sales_preds = '''\n",
        "                                SELECT *\n",
        "                                FROM analytics.refined_sales_orders_forecast\n",
        "                                '''\n",
        "\n",
        "df_predictions = spark.sql(str_select_sales_preds).toPandas()\n",
        "df_predictions.set_index('dt', inplace=True)\n",
        "df_predictions.sort_index(inplace=True)\n",
        "\n",
        "df_predictions.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Including actual values in predicted data\n",
        "df_predictions['NET_VALUE_real'] = df_series_sales_resampled['NET_VALUE']\n",
        "df_predictions.dropna(inplace=True)\n",
        "df_predictions.sort_index(inplace=True)\n",
        "\n",
        "df_predictions.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importing existing metrics\n",
        "str_select_metrics = '''\n",
        "                                SELECT *\n",
        "                                FROM analytics.refined_sales_orders_forecast_model_metrics\n",
        "                                '''\n",
        "\n",
        "df_current_metrics = spark.sql(str_select_metrics).toPandas()\n",
        "\n",
        "df_current_metrics.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 3. Calculating Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def calculate_wape(y, yhat):\n",
        "    \"\"\"\n",
        "    Calculates Weighted Absolute Percentage Error (WAPE).\n",
        "    \n",
        "    Args:\n",
        "        y (list or numpy array): Actual values.\n",
        "        yhat (list or numpy array): Predicted values.\n",
        "    \n",
        "    Returns:\n",
        "        float: WAPE value.\n",
        "        \n",
        "    Description:\n",
        "    This function calculates the Weighted Absolute Percentage Error (WAPE).\n",
        "    \n",
        "    WAPE takes into account both absolute error and percentage error between actual and predicted values. \n",
        "    Furthermore, it performs error weighting based on actual values. In seasonal sales time series scenarios, \n",
        "    seasonal peak periods are assigned a higher weight, so errors in these periods have a more significant impact on this metric.\n",
        "    \n",
        "    Weighting is performed by assigning higher weights to larger actual values, since errors in high demand periods \n",
        "    can have a more relevant impact on planning decisions and financial results.\n",
        "    \n",
        "    In the code section where weight is defined as 'weight = actual', it is considered that the weight of each observation \n",
        "    is equal to the actual value of that observation itself. This means that when calculating WAPE, absolute percentage errors \n",
        "    are multiplied by the actual values themselves before being summed to calculate total weighted error.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initializes variables to store total WAPE and total weights\n",
        "    total_wape = 0\n",
        "    total_weight = 0\n",
        "    \n",
        "    try:\n",
        "        # Loop over actual (y) and predicted (yhat) values\n",
        "        for i in range(len(y)):\n",
        "            actual = y[i]  # Actual value\n",
        "            predicted = yhat[i]  # Predicted value\n",
        "            \n",
        "            # Calculates absolute error between actual and predicted value\n",
        "            absolute_error = abs(actual - predicted)\n",
        "            \n",
        "            # Calculates absolute percentage error\n",
        "            absolute_percentage_error = absolute_error / actual\n",
        "            \n",
        "            # Calculates weight as the actual value (used for weighting)\n",
        "            weight = actual\n",
        "            \n",
        "            # Updates total WAPE summing weighted percentage error\n",
        "            total_wape += absolute_percentage_error * weight\n",
        "            \n",
        "            # Updates total weights\n",
        "            total_weight += weight\n",
        "        \n",
        "        # Calculates final WAPE as weighted average of percentage errors\n",
        "        wape = total_wape / total_weight * 100\n",
        "    except:\n",
        "        # If an exception occurs (e.g., division by zero), sets WAPE as infinite\n",
        "        wape = np.inf\n",
        "        \n",
        "    return wape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Separating necessary columns to calculate metrics\n",
        "df_predictions_calc = df_predictions[['forecast_NET_VALUE_quartile_0_5', 'NET_VALUE_real', 'dt_predict']].rename(columns={'forecast_NET_VALUE_quartile_0_5': 'NET_VALUE_predicted'})\n",
        "display(df_predictions_calc.reset_index())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generating series\n",
        "metrics_lists = {\n",
        "    'mape': [], 'smape': [], 'ope': [], 'r2': [], 'rmse': [], 'wape': []\n",
        "    }\n",
        "\n",
        "# For each prediction batch, perform metric calculation\n",
        "for dt_predict in df_predictions_calc.dt_predict.unique():\n",
        "    \n",
        "    # Creates series for metric calculation\n",
        "    actual = TimeSeries.from_dataframe(df_predictions_calc[df_predictions_calc.dt_predict == dt_predict][['NET_VALUE_real']])\n",
        "    predicted = TimeSeries.from_dataframe(df_predictions_calc[df_predictions_calc.dt_predict == dt_predict][['NET_VALUE_predicted']])\n",
        "\n",
        "    # Calculates metrics\n",
        "    mape = metrics.mape(actual + 1, predicted + 1)\n",
        "    smape = metrics.smape(actual + 1, predicted + 1)\n",
        "    ope = metrics.ope(actual + 1, predicted + 1)\n",
        "    r2 = metrics.r2_score(actual + 1, predicted + 1)\n",
        "    rmse = metrics.rmse(actual + 1, predicted + 1)\n",
        "    wape = calculate_wape(actual + 1, predicted + 1)\n",
        "\n",
        "    metrics_lists['mape'].append(mape)\n",
        "    metrics_lists['smape'].append(smape)\n",
        "    metrics_lists['ope'].append(ope)\n",
        "    metrics_lists['r2'].append(r2)\n",
        "    metrics_lists['rmse'].append(rmse)\n",
        "    metrics_lists['wape'].append(wape.values().squeeze().item())\n",
        "\n",
        "# Generates metrics dataframe\n",
        "df_metrics = pd.DataFrame(metrics_lists)\n",
        "df_metrics['dt_predict'] = pd.to_datetime(df_predictions_calc.dt_predict.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspecting df_metrics\n",
        "df_metrics.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspecting main metrics\n",
        "display(df_metrics[df_metrics.dt_predict.dt.day_of_week < 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspecting actual vs predicted\n",
        "display(df_predictions.reset_index())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspecting projection with historical actuals\n",
        "display(pd.concat([df_series_sales_resampled.reset_index().iloc[-500:],\n",
        "           df_predictions.reset_index().rename(columns={'dt': 'SYSTEM_TIMESTAMP'})], \n",
        "          axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Checking current model generation date\n",
        "model_stage = 'staging'\n",
        "mlflow_model_name = 'LightGBM_forecast_sales_daily'\n",
        "client = MlflowClient()\n",
        "model_metadata = client.get_latest_versions(mlflow_model_name, stages=[model_stage])\n",
        "\n",
        "# Getting creation timestamp of latest version\n",
        "creation_timestamp = model_metadata[0].creation_timestamp\n",
        "\n",
        "# Formatting date\n",
        "formatted_date = (datetime.datetime.fromtimestamp(creation_timestamp / 1000.0) - timedelta(hours=3)).strftime('%Y-%m-%d %H:%M')\n",
        "formatted_date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data for calculation\n",
        "control_metric = 'wape'\n",
        "df = df_metrics.set_index('dt_predict')[[control_metric]].sort_index()\n",
        "\n",
        "# Calculation of process statistics\n",
        "total_mean = df[control_metric].mean()\n",
        "std_dev = df[control_metric].std()\n",
        "\n",
        "# Calculate Moving Range (MR)\n",
        "df['MR'] = df[control_metric].diff().abs()\n",
        "\n",
        "# Calculate Moving Range mean\n",
        "mr_mean = df['MR'][1:].mean()  # Ignora o primeiro valor que Ã© NaN\n",
        "\n",
        "# Control Limits for I-MR\n",
        "UCL_I = total_mean + 3 * std_dev\n",
        "LCL_I = total_mean - 3 * std_dev\n",
        "UCL_MR = mr_mean * 3.267  # 3.267 is a constant for moving range in I-MR chart\n",
        "\n",
        "# Functions for feature detection\n",
        "def detect_sequence(data, cut_date, n=5):\n",
        "    '''\n",
        "    Detects existence of n consecutive points above the mean line.\n",
        "    '''\n",
        "    sequence_points = []\n",
        "    count = 0\n",
        "    for i, value in enumerate(data):\n",
        "        if df.iloc[i].name > pd.Timestamp(cut_date):\n",
        "            if value > total_mean:\n",
        "                count += 1\n",
        "                if count >= n:\n",
        "                    sequence_points.extend(list(range(i - count + 1, i + 1)))\n",
        "            else:\n",
        "                count = 0\n",
        "    return sequence_points\n",
        "\n",
        "def detect_trend(data, cut_date, window=7):\n",
        "    '''\n",
        "    Detects upward or downward trends within a threshold.\n",
        "    '''\n",
        "    trend_points = []\n",
        "    for i in range(len(data) - window + 1):\n",
        "        if df.iloc[i].name > pd.Timestamp(cut_date):\n",
        "            segment = data[i:i+window]\n",
        "            if np.polyfit(range(len(segment)), segment, 1)[0] > 0:\n",
        "                trend_points.append(i)\n",
        "    return trend_points\n",
        "\n",
        "def detect_control_limits(data, cut_date, UCL, LCL):\n",
        "    '''\n",
        "    Detects points outside control limits.\n",
        "    '''\n",
        "    out_of_control_points = []\n",
        "    for i, point in enumerate(data):\n",
        "        if df.iloc[i].name > pd.Timestamp(cut_date):\n",
        "            if point > UCL or point < LCL:\n",
        "                out_of_control_points.append(i)\n",
        "    return out_of_control_points\n",
        "\n",
        "# Feature detection\n",
        "sequence_points = detect_sequence(df[control_metric], formatted_date)\n",
        "trend_points = detect_trend(df[control_metric], formatted_date)\n",
        "control_limit_points_I = detect_control_limits(df[control_metric], formatted_date, UCL_I, LCL_I)\n",
        "control_limit_points_MR = detect_control_limits(df['MR'][1:], formatted_date, UCL_MR, 0)  # Ignores first value which is NaN\n",
        "\n",
        "# Plotting Control Charts with Plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "# Chart I (Individuals)\n",
        "fig.add_trace(go.Scatter(x=df.index, y=df[control_metric], mode='lines+markers', name=control_metric))\n",
        "\n",
        "# Add CL, UCL and LCL lines as horizontal lines\n",
        "fig.add_shape(type='line',\n",
        "              x0=df.index[0], y0=total_mean, x1=df.index[-1], y1=total_mean,\n",
        "              line=dict(color='green', width=1, dash='dash'))\n",
        "fig.add_shape(type='line',\n",
        "              x0=df.index[0], y0=UCL_I, x1=df.index[-1], y1=UCL_I,\n",
        "              line=dict(color='red', width=1, dash='dash'))\n",
        "fig.add_shape(type='line',\n",
        "              x0=df.index[0], y0=LCL_I, x1=df.index[-1], y1=LCL_I,\n",
        "              line=dict(color='red', width=1, dash='dash'))\n",
        "\n",
        "# Mark detected points\n",
        "fig.add_trace(go.Scatter(x=df.index[sequence_points], y=df[control_metric].iloc[sequence_points],\n",
        "                         mode='markers', name='Sequence', marker=dict(color='purple', symbol='circle')))\n",
        "fig.add_trace(go.Scatter(x=df.index[trend_points], y=df[control_metric].iloc[trend_points],\n",
        "                         mode='markers', name='Trend', marker=dict(color='orange', symbol='circle')))\n",
        "fig.add_trace(go.Scatter(x=df.index[control_limit_points_I], y=df[control_metric].iloc[control_limit_points_I],\n",
        "                         mode='markers', name='Out of Limits', marker=dict(color='black', symbol='circle')))\n",
        "\n",
        "# Layout for Chart I\n",
        "fig.update_layout(title='Control Chart I (Individuals)',\n",
        "                  xaxis_title='Date',\n",
        "                  yaxis_title=control_metric)\n",
        "\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# Chart MR (Moving Range)\n",
        "fig_MR = go.Figure()\n",
        "fig_MR.add_trace(go.Scatter(x=df.index[1:], y=df['MR'].iloc[1:], mode='lines+markers', name='MR'))\n",
        "\n",
        "# Add UCL_MR, CL_MR lines as horizontal lines\n",
        "fig_MR.add_trace(go.Scatter(x=df.index[::], y=[UCL_MR]*len(df), mode='lines', line=dict(color='red', width=1, dash='dash'), name='UCL (MR)'))\n",
        "\n",
        "# Add CL_MR line as horizontal line\n",
        "fig_MR.add_trace(go.Scatter(x=df.index[::], y=[mr_mean]*len(df), mode='lines', line=dict(color='green', width=1, dash='dash'), name='CL (MR)'))\n",
        "\n",
        "# Mark points outside limits in MR chart\n",
        "fig_MR.add_trace(go.Scatter(x=df.index[1:][control_limit_points_MR], y=df['MR'].iloc[1:].iloc[control_limit_points_MR],\n",
        "                            mode='markers', name='Out of Limits (MR)', marker=dict(color='black', symbol='circle')))\n",
        "\n",
        "# Layout for Chart MR\n",
        "fig_MR.update_layout(title='Control Chart MR (Moving Range)',\n",
        "                     xaxis_title='Date',\n",
        "                     yaxis_title='Moving Range')\n",
        "\n",
        "# Show MR chart\n",
        "fig_MR.show()\n",
        "\n",
        "# Report of detected features\n",
        "print(\"\\nSequence Points:\")\n",
        "for point in df.iloc[sequence_points].index.values:\n",
        "    print(\"-\", str(pd.to_datetime(point)))\n",
        "\n",
        "print(\"\\nTrend Points:\")\n",
        "for point in df.iloc[trend_points].index.values:\n",
        "    print(\"-\", str(pd.to_datetime(point)))\n",
        "\n",
        "print(\"\\nPoints Out of Control Limits I:\")\n",
        "for point in df.iloc[control_limit_points_I].index.values:\n",
        "    print(\"-\", str(pd.to_datetime(point)))\n",
        "\n",
        "print(\"\\nPoints Out of Control Limits MR:\")\n",
        "for point in df.iloc[control_limit_points_MR].index.values:\n",
        "    print(\"-\", str(pd.to_datetime(point)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Checking the need for model retraining\n",
        "if len(sequence_points) > 0:\n",
        "    print('Consecutive points above mean!')\n",
        "    print('Retrain the model!')\n",
        "    result = 'retrain'\n",
        "else:\n",
        "    print('No abnormality.')\n",
        "    print('Model retraining unnecessary!')\n",
        "    result = 'keep'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Adding calculated columns to dataframe\n",
        "df['UCL_I'] = UCL_I\n",
        "df['LCL_I'] = LCL_I\n",
        "df['UCL_MR'] = UCL_MR\n",
        "df['CL_MR'] = mr_mean\n",
        "df['Flag_Out_Limit_I'] = 0\n",
        "df['Flag_Out_Limit_MR'] = 0\n",
        "df['Flag_Sequence'] = 0\n",
        "df['Flag_Trend'] = 0\n",
        "\n",
        "# Mark points out of control limits\n",
        "df.loc[df.index[control_limit_points_I], 'Flag_Out_Limit_I'] = 1\n",
        "df.loc[df.index[1:][control_limit_points_MR], 'Flag_Out_Limit_MR'] = 1\n",
        "\n",
        "# Mark sequence points\n",
        "df.loc[df.index[sequence_points], 'Flag_Sequence'] = 1\n",
        "\n",
        "# Mark trend points\n",
        "df.loc[df.index[trend_points], 'Flag_Trend'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Including statistical control data in metrics\n",
        "df_metrics = df_metrics.merge(df.reset_index(drop=False).rename(columns={'SYSTEM_TIMESTAMP': 'dt_predict'}).drop(labels=[control_metric], axis=1), on='dt_predict', how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Checking data to be saved\n",
        "df_metrics[df_metrics.dt_predict > df_current_metrics.dt_predict.max()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Saving data to table. Only new data\n",
        "if len(df_metrics[df_metrics.dt_predict > df_current_metrics.dt_predict.max()]) > 0:\n",
        "    df_spark = spark.createDataFrame(df_metrics[df_metrics.dt_predict > df_current_metrics.dt_predict.max()]) \n",
        "    mode = 'append' # overwrite or append\n",
        "    overwriteSchema = 'False' # True or False\n",
        "    table_name = 'analytics.refined_sales_orders_forecast_model_metrics'\n",
        "    #path = '/dbfs/mnt/datalake/datascience/raw/forecast_sales/model_metrics/'\n",
        "\n",
        "    df_spark.write.option(\"overwriteSchema\", overwriteSchema).saveAsTable(table_name, \n",
        "                                                                        format='delta', \n",
        "                                                                        mode=mode,\n",
        "                                                                        #path=f'{path}model_metrics')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Returns whether retraining should happen. This output is used by the Synapse pipeline to trigger the retraining notebook if necessary.\n",
        "dbutils.notebook.exit(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}